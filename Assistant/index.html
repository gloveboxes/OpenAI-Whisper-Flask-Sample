<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Assistant">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">Start the Home Assistant | Build a home assistant with OpenAI Whisper and Functions</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://gloveboxes.github.io/OpenAI-Whisper-Transcriber-Sample/Assistant/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Start the Home Assistant | Build a home assistant with OpenAI Whisper and Functions"><meta data-rh="true" name="description" content="Clone the repository"><meta data-rh="true" property="og:description" content="Clone the repository"><link data-rh="true" rel="icon" href="/OpenAI-Whisper-Transcriber-Sample/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://gloveboxes.github.io/OpenAI-Whisper-Transcriber-Sample/Assistant/"><link data-rh="true" rel="alternate" href="https://gloveboxes.github.io/OpenAI-Whisper-Transcriber-Sample/Assistant/" hreflang="en"><link data-rh="true" rel="alternate" href="https://gloveboxes.github.io/OpenAI-Whisper-Transcriber-Sample/Assistant/" hreflang="x-default"><script>!function(t,e,n,a,c,s,r){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(s=e.createElement(a)).async=1,s.src="https://www.clarity.ms/tag/hf3ajlszfy",(r=e.getElementsByTagName(a)[0]).parentNode.insertBefore(s,r)}(window,document,"clarity","script")</script><link rel="stylesheet" href="/OpenAI-Whisper-Transcriber-Sample/assets/css/styles.64843db6.css">
<link rel="preload" href="/OpenAI-Whisper-Transcriber-Sample/assets/js/runtime~main.f4bb35d7.js" as="script">
<link rel="preload" href="/OpenAI-Whisper-Transcriber-Sample/assets/js/main.db9f1d45.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><a class="navbar__brand" href="/OpenAI-Whisper-Transcriber-Sample/"><div class="navbar__logo"><img src="/OpenAI-Whisper-Transcriber-Sample/img/Azure-OpenAI-Services.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/OpenAI-Whisper-Transcriber-Sample/img/Azure-OpenAI-Services.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Build a home assistant with OpenAI Whisper and Functions.</b></a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/OpenAI-Whisper-Transcriber-Sample/">Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/OpenAI-Whisper-Transcriber-Sample/OpenAI-Functions/">Intro to OpenAI Functions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/OpenAI-Whisper-Transcriber-Sample/Assistant/">Start the Home Assistant</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/OpenAI-Whisper-Transcriber-Sample/category/create-a-whisper-endpoint/">Create a Whisper Endpoint</a><button aria-label="Toggle the collapsible sidebar category &#x27;Create a Whisper Endpoint&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/OpenAI-Whisper-Transcriber-Sample/category/transcribe-with-whisper/">Transcribe with Whisper</a><button aria-label="Toggle the collapsible sidebar category &#x27;Transcribe with Whisper&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/OpenAI-Whisper-Transcriber-Sample/Proxies/Whisper-intranet/">Proxies</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/OpenAI-Whisper-Transcriber-Sample/Testing/Whisper-Postman/">Testing</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/OpenAI-Whisper-Transcriber-Sample/Summary/">Finished</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/OpenAI-Whisper-Transcriber-Sample/References/">References</a></li></ul></nav></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/OpenAI-Whisper-Transcriber-Sample/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Start the Home Assistant</span><meta itemprop="position" content="1"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Start the Home Assistant</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="clone-the-repository">Clone the repository<a href="#clone-the-repository" class="hash-link" aria-label="Direct link to Clone the repository" title="Direct link to Clone the repository">​</a></h2><ol><li><p>Install Git from <a href="https://git-scm.com/downloads" target="_blank" rel="noopener noreferrer">https://git-scm.com/downloads</a>.</p></li><li><p>Clone the repository:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">git</span><span class="token plain"> clone https://github.com/gloveboxes/OpenAI-Whisper-Transcriber-Sample</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="environment-file">Environment file<a href="#environment-file" class="hash-link" aria-label="Direct link to Environment file" title="Direct link to Environment file">​</a></h2><p>You&#x27;ll find a <code>.env</code> file in the <code>client</code> folder of the repo you cloned. This file contains the configuration settings for the Home Assistant app.</p><p>The following keys are defined in the <code>.env</code> file:</p><table><thead><tr><th>Key</th><th>Description</th></tr></thead><tbody><tr><td>OPENAI_API_KEY</td><td>The OpenAI API key.</td></tr><tr><td>WEATHER_API_KEY</td><td>The Weather API key.</td></tr><tr><td>WHISPER_MODE</td><td>The Whisper speech to text transcriber mode. The default mode is <code>local</code>.</td></tr><tr><td>WHISPER_MODEL_NAME</td><td>The Whisper speech to text transcriber model name. The default model is <code>tiny</code>. This is only used when the <code>WHISPER_MODE</code> is set to <code>local</code>. See <a href="#whisper-models">Whisper models</a> for more information.</td></tr><tr><td>WHISPER_ENDPOINT</td><td>The Whisper speech to text transcriber endpoint. This is only used when the <code>WHISPER_MODE</code> is set to <code>gpu</code>.</td></tr><tr><td>WHISPER_API_KEY</td><td>The Whisper speech to text transcriber API key. This is only used when the <code>WHISPER_MODE</code> is set to <code>gpu</code>.</td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_LWe7" id="cloud-api-keys">Cloud API Keys<a href="#cloud-api-keys" class="hash-link" aria-label="Direct link to Cloud API Keys" title="Direct link to Cloud API Keys">​</a></h2><p>The Home Assistant uses the following cloud services:</p><ol><li><a href="https://platform.openai.com" target="_blank" rel="noopener noreferrer">OpenAI</a> chat and depending on your configuration, the <code>Whisper</code> speech to text transcriber. The OpenAI API key is used to call the OpenAI Chat Completion API and extracting OpenAI Functions.</li><li>The <a href="https://www.weatherapi.com/" target="_blank" rel="noopener noreferrer">Weather API</a> to get weather data. This data is used to <code>ground</code> the GPT prompts the assistant generates.</li></ol><p>Next you will need to create accounts and get API keys for the cloud services. The API keys are stored in a <code>.env</code> file in the <code>client</code> folder of the repo you cloned. As you create the API keys, add them to the <code>.env</code> file.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="openai-api">OpenAI API<a href="#openai-api" class="hash-link" aria-label="Direct link to OpenAI API" title="Direct link to OpenAI API">​</a></h3><p>Create an OpenAI account and get an API key.</p><ol><li>Sign up for an OpenAI account at <a href="https://platform.openai.com" target="_blank" rel="noopener noreferrer">https://platform.openai.com</a>.</li><li>Create an API key at <a href="https://platform.openai.com/account/api-keys" target="_blank" rel="noopener noreferrer">https://platform.openai.com/account/api-keys</a>.</li><li>Update the OPENAI_API_KEY key in the <code>.env</code> file with the API key.</li><li>Save the updated <code>.env</code> file.</li></ol><h3 class="anchor anchorWithStickyNavbar_LWe7" id="weather-api">Weather API<a href="#weather-api" class="hash-link" aria-label="Direct link to Weather API" title="Direct link to Weather API">​</a></h3><p>Create a Weather API account and get an API key.</p><ol><li>Sign up for a <a href="https://www.weatherapi.com/signup.aspx" target="_blank" rel="noopener noreferrer">Weather API account</a>.</li><li>Create a free <a href="https://www.weatherapi.com/my/" target="_blank" rel="noopener noreferrer">Weather API key</a>.</li><li>Update the WEATHER_API_KEY key in the <code>.env</code> file with the API key.</li><li>Save the updated <code>.env</code> file.</li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="install-prerequisites">Install prerequisites<a href="#install-prerequisites" class="hash-link" aria-label="Direct link to Install prerequisites" title="Direct link to Install prerequisites">​</a></h2><ol><li><p>Install <a href="https://www.python.org/downloads" target="_blank" rel="noopener noreferrer">Python</a> version 3.8 ~ 3.10. The <a href="https://pypi.org/project/openai-whisper/" target="_blank" rel="noopener noreferrer">Whisper library</a> is supported on Python 3.8 to 3.10.</p></li><li><p>Install the required Python packages:</p></li><li><p>Create a Python virtual environment:</p><p>Windows</p><div class="language-pwsh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-pwsh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">python -m venv .assistant</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Linux and macOS</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">python3 -m venv .assistant</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></li><li><p>Activate the Python virtual environment:</p><p>Windows</p><div class="language-pwsh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-pwsh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">./.assistant/Scripts/activate</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Linux and macOS</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">source</span><span class="token plain"> .assistant/bin/activate</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></li><li><p>Install the required Python packages:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> -r requirements.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></li><li><p>On Windows, by default, the <code>requirements.txt</code> file will install the CPU version of PyTorch. If you have an NVidia GPU, you can install the CUDA accelerated version of PyTorch.</p><ol><li><p>First uninstall the CPU version of PyTorch:</p><div class="language-pwsh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-pwsh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip3 uninstall torch torchvision torchaudio</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></li><li><p>Install the CUDA accelerated version of PyTorch:</p><p>Review the <a href="https://pytorch.org/get-started/locally/" target="_blank" rel="noopener noreferrer">PyTorch website</a> for the latest installation instructions.</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">pip3 </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></li></ol></li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="set-the-text-to-speech-transcriber-mode">Set the Text to Speech Transcriber mode<a href="#set-the-text-to-speech-transcriber-mode" class="hash-link" aria-label="Direct link to Set the Text to Speech Transcriber mode" title="Direct link to Set the Text to Speech Transcriber mode">​</a></h2><p>There are three modes to use Whisper speech to text transcriber. The default mode is <code>local</code>. You can change the mode by updating the <code>WHISPER_MODE</code> key in the <code>.env</code> file.</p><ol><li><code>local</code>: The Whisper speech to text transcription is done locally on the device. This is the default mode and free mode. The speed will depend on the hardware capabilities of your computer. The first time the Whisper speech to text transcriber is used, it will download the transcriber model from the internet. This will take a few minutes.</li><li><code>openai</code>: The Whisper speech to text transcription is done using the OpenAI API Audio service which maybe a lot faster that transcribing speech on your computer. This is a paid service, review <a href="https://openai.com/pricing/" target="_blank" rel="noopener noreferrer">OpenAI Audio Model Pricing</a> for more information.</li><li><code>gpu</code>: You can run a Whisper REST endpoint on your own NVidia GPU. For more information, review the <a href="/OpenAI-Whisper-Transcriber-Sample/Whisper-Server/Whisper-Server-Setup/">Whisper REST API</a> docs.</li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="run-the-home-assistant-app">Run the home assistant app<a href="#run-the-home-assistant-app" class="hash-link" aria-label="Direct link to Run the home assistant app" title="Direct link to Run the home assistant app">​</a></h2><ol><li><p>Ensure the Python virtual environment is activated.</p></li><li><p>From the command line, change to the <code>client</code> folder of the repo you cloned.</p></li><li><p>Run the home assistant app:</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">python assistant.py</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></li><li><p>The App will start, select your preferred microphone from the dropdown menu.</p><p><img loading="lazy" alt="Home Assistant" src="/OpenAI-Whisper-Transcriber-Sample/assets/images/home_assistant-52ff09e09d57238fb4163a7a59697e74.png" width="3264" height="1658" class="img_ev3q"></p></li><li><p>You can tweak the <code>Energy Threshold</code>. The Energy Threshold represents the energy level threshold for sounds. Values below this threshold are considered silence, and values above this threshold are considered speech. For more information on this setting, review <a href="https://github.com/Uberi/speech_recognition/blob/master/reference/library-reference.rst#recognizer_instanceenergy_threshold--300---type-float" target="_blank" rel="noopener noreferrer">recognizer_instance.energy_threshold</a>.</p></li><li><p>Press <code>Microphone</code> button to start listening for your voice commands. Try out a few commands like:</p><ol><li>What&#x27;s the weather in Seattle</li><li>How can you help me</li><li>Turn on the living room lights</li><li>Turn in the living room lights set the color to orange and brightness to dim.</li><li>Turn on the washing machine</li><li>Lock the front door</li></ol></li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="whisper-models">Whisper Models<a href="#whisper-models" class="hash-link" aria-label="Direct link to Whisper Models" title="Direct link to Whisper Models">​</a></h2><p>The Whisper speech to text transcriber default model name is <code>tiny</code>. You can change the model name by updating the <code>WHISPER_MODEL_NAME</code> key in the <code>.env</code> file.</p><p>The following table lists the available Whisper speech to text transcriber model names. The performance of the transcriber will depend on the model name you select and the hardware capabilities of your computer. </p><p>Remember, if you don&#x27;t have the hardware to run the models with sufficient performance, you can use the OpenAI API Audio service by setting the <code>WHISPER_MODE</code> environment variable to <code>openai</code>. </p><p>The OpenAI API Audio service is a paid service, review <a href="https://openai.com/pricing/" target="_blank" rel="noopener noreferrer">OpenAI Audio Model Pricing</a> for more information.</p><p><img loading="lazy" src="/OpenAI-Whisper-Transcriber-Sample/assets/images/whisper_model_selection-fe215cf6a783f1f3c31a03892f7bcf8d.png" width="1583" height="568" class="img_ev3q"></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/gloveboxes/OpenAI-Whisper-Transcriber-Sample/tree/master/docs/docs/20-Assistant.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/OpenAI-Whisper-Transcriber-Sample/OpenAI-Functions/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Intro to OpenAI Functions</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/OpenAI-Whisper-Transcriber-Sample/category/create-a-whisper-endpoint/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Create a Whisper Endpoint</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#clone-the-repository" class="table-of-contents__link toc-highlight">Clone the repository</a></li><li><a href="#environment-file" class="table-of-contents__link toc-highlight">Environment file</a></li><li><a href="#cloud-api-keys" class="table-of-contents__link toc-highlight">Cloud API Keys</a><ul><li><a href="#openai-api" class="table-of-contents__link toc-highlight">OpenAI API</a></li><li><a href="#weather-api" class="table-of-contents__link toc-highlight">Weather API</a></li></ul></li><li><a href="#install-prerequisites" class="table-of-contents__link toc-highlight">Install prerequisites</a></li><li><a href="#set-the-text-to-speech-transcriber-mode" class="table-of-contents__link toc-highlight">Set the Text to Speech Transcriber mode</a></li><li><a href="#run-the-home-assistant-app" class="table-of-contents__link toc-highlight">Run the home assistant app</a></li><li><a href="#whisper-models" class="table-of-contents__link toc-highlight">Whisper Models</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Build a home assistant with OpenAI Whisper and Functions Workshop. Built with Docusaurus.</div></div></div></footer></div>
<script src="/OpenAI-Whisper-Transcriber-Sample/assets/js/runtime~main.f4bb35d7.js"></script>
<script src="/OpenAI-Whisper-Transcriber-Sample/assets/js/main.db9f1d45.js"></script>
</body>
</html>