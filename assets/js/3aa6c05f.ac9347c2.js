"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[893],{4137:(e,t,r)=>{r.d(t,{Zo:()=>m,kt:()=>d});var n=r(7294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function i(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function p(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?i(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):i(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},i=Object.keys(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)r=i[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var o=n.createContext({}),s=function(e){var t=n.useContext(o),r=t;return e&&(r="function"==typeof e?e(t):p(p({},t),e)),r},m=function(e){var t=s(e.components);return n.createElement(o.Provider,{value:t},e.children)},u="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,i=e.originalType,o=e.parentName,m=l(e,["components","mdxType","originalType","parentName"]),u=s(r),c=a,d=u["".concat(o,".").concat(c)]||u[c]||h[c]||i;return r?n.createElement(d,p(p({ref:t},m),{},{components:r})):n.createElement(d,p({ref:t},m))}));function d(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=r.length,p=new Array(i);p[0]=c;var l={};for(var o in t)hasOwnProperty.call(t,o)&&(l[o]=t[o]);l.originalType=e,l[u]="string"==typeof e?e:a,p[1]=l;for(var s=2;s<i;s++)p[s]=r[s];return n.createElement.apply(null,p)}return n.createElement.apply(null,r)}c.displayName="MDXCreateElement"},587:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>o,contentTitle:()=>p,default:()=>h,frontMatter:()=>i,metadata:()=>l,toc:()=>s});var n=r(7462),a=(r(7294),r(4137));const i={},p="Ubuntu with an NVidia GPU",l={unversionedId:"Whisper-Server/Whisper-Server-Ubuntu",id:"Whisper-Server/Whisper-Server-Ubuntu",title:"Ubuntu with an NVidia GPU",description:"The recommended configuration for running the OpenAI Whisper sample on Ubuntu is:",source:"@site/docs/30-Whisper-Server/22-Whisper-Server-Ubuntu.md",sourceDirName:"30-Whisper-Server",slug:"/Whisper-Server/Whisper-Server-Ubuntu",permalink:"/OpenAI-Whisper-Transcriber-Sample/Whisper-Server/Whisper-Server-Ubuntu",draft:!1,editUrl:"https://github.com/gloveboxes/OpenAI-Whisper-Transcriber-Sample/tree/master/docs/docs/30-Whisper-Server/22-Whisper-Server-Ubuntu.md",tags:[],version:"current",sidebarPosition:22,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Windows with an NVidia GPU",permalink:"/OpenAI-Whisper-Transcriber-Sample/Whisper-Server/Whisper-Server-WSL"},next:{title:"Systems without an NVidia GPU",permalink:"/OpenAI-Whisper-Transcriber-Sample/Whisper-Server/Whisper-Server-no-GPU"}},o={},s=[{value:"Install the NVidia GPU Drivers",id:"install-the-nvidia-gpu-drivers",level:3},{value:"Install Ubuntu prerequisites",id:"install-ubuntu-prerequisites",level:2},{value:"Start the Whisper Transcriber Service",id:"start-the-whisper-transcriber-service",level:2}],m={toc:s},u="wrapper";function h(e){let{components:t,...i}=e;return(0,a.kt)(u,(0,n.Z)({},m,i,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"ubuntu-with-an-nvidia-gpu"},"Ubuntu with an NVidia GPU"),(0,a.kt)("p",null,"The recommended configuration for running the OpenAI Whisper sample on Ubuntu is:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The Whisper Transcriber Service was tested on Ubuntu 20.04 LTS.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Ubuntu 20.04 includes Python 3.8."),(0,a.kt)("p",{parentName:"li"},"As At June 2023, the ",(0,a.kt)("a",{parentName:"p",href:"https://pypi.org/project/openai-whisper/"},"OpenAI Whisper library")," is compatible with Python 3.8-3.10")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"An NVidia GPU with 10 to 12 GB of VRAM. But you can run smaller Whisper models on GPUs with less VRAM.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"A modern CPU with 16 GB of RAM. With a GPU, the CPU is not heavily used, but you need enough RAM to run the OS and the Whisper Transcriber Service."))),(0,a.kt)("h3",{id:"install-the-nvidia-gpu-drivers"},"Install the NVidia GPU Drivers"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Install the NVidia GPU drivers. See the ",(0,a.kt)("a",{parentName:"li",href:"https://www.nvidia.com/Download/index.aspx"},"NVidia website")," for instructions.")),(0,a.kt)("h2",{id:"install-ubuntu-prerequisites"},"Install Ubuntu prerequisites"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Ensure the Ubuntu system is up to date.",(0,a.kt)("ol",{parentName:"li"},(0,a.kt)("li",{parentName:"ol"},"Open a terminal window."),(0,a.kt)("li",{parentName:"ol"},"Run:",(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"sudo apt update && sudo apt upgrade\n"))),(0,a.kt)("li",{parentName:"ol"},"Restart if necessary."))),(0,a.kt)("li",{parentName:"ol"},"Install the dependencies. ",(0,a.kt)("ol",{parentName:"li"},(0,a.kt)("li",{parentName:"ol"},"Run:",(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"sudo apt install ffmpeg python3-pip python3-venv\n"))),(0,a.kt)("li",{parentName:"ol"},"Test FFmpeg. Run ",(0,a.kt)("inlineCode",{parentName:"li"},"ffmpeg -version"),", the command should return the FFmpeg version.")))),(0,a.kt)("h2",{id:"start-the-whisper-transcriber-service"},"Start the Whisper Transcriber Service"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"From a terminal window.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Clone the Whisper Transcriber Sample to your preferred repo folder."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/gloveboxes/OpenAI-Whisper-Transcriber-Sample.git\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Navigate to the ",(0,a.kt)("inlineCode",{parentName:"p"},"server")," folder."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"cd OpenAI-Whisper-Transcriber-Sample/server\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Create a Python virtual environment."),(0,a.kt)("admonition",{parentName:"li",type:"danger"},(0,a.kt)("p",{parentName:"admonition"},"At the time of writing (June 2023), the ",(0,a.kt)("a",{parentName:"p",href:"https://pypi.org/project/openai-whisper"},"Whisper Python library")," is supported on Python 3.8 to 3.10. The Whisper library worked on Python 3.11.3, but not Python 3.11.4. Be sure to check the version of Python you are using ",(0,a.kt)("inlineCode",{parentName:"p"},"python3 --version"),".")),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"python3 -m venv .whisper-venv\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Activate the Python virtual environment."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"source .whisper-venv/bin/activate\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Install the required Python libraries."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"pip3 install -r requirements.txt\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Test that CUDA/GPU is available to PyTorch."),(0,a.kt)("p",{parentName:"li"},"Run the following command, if CUDA is available, the command will return ",(0,a.kt)("inlineCode",{parentName:"p"},"True"),"."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'python3 -c "import torch; print(torch.cuda.is_available())"\n'))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Review the following chart is taken from the ",(0,a.kt)("a",{parentName:"p",href:"https://pypi.org/project/openai-whisper/"},"OpenAI Whisper Project Description")," page and select the model that will fit in the VRAM of your GPU. At the time of writing, Whisper multilingual models include ",(0,a.kt)("inlineCode",{parentName:"p"},"tiny"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"small"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"medium"),", and ",(0,a.kt)("inlineCode",{parentName:"p"},"large"),", and English-only models include ",(0,a.kt)("inlineCode",{parentName:"p"},"tiny.en"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"small.en"),", and ",(0,a.kt)("inlineCode",{parentName:"p"},"medium.en"),".\n",(0,a.kt)("img",{src:r(6120).Z,width:"1583",height:"568"}))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Update the ",(0,a.kt)("inlineCode",{parentName:"p"},"server/config.json")," file to set your desired Whisper model. For example, to use the ",(0,a.kt)("inlineCode",{parentName:"p"},"medium")," model, set the ",(0,a.kt)("inlineCode",{parentName:"p"},"model")," property to ",(0,a.kt)("inlineCode",{parentName:"p"},"medium"),"."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-json"},'{ "model": "medium" }\n'))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Start the Whisper Transcriber Service. From the command line, run:"),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"uvicorn main:app --port 5500 --host 0.0.0.0\n")),(0,a.kt)("p",{parentName:"li"},"   Once the Whisper Transcriber Service starts, you should see output similar to the following."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-text"},"[2023-06-04 18:53:46.194411] Whisper API Key: 17ce01e9-ac65-49c8-9cc9-18d8deb78197\n[2023-06-04 18:53:50.375244] Model: medium loaded.\n[2023-06-04 18:53:50.375565] Ready to transcribe audio files.\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The ",(0,a.kt)("inlineCode",{parentName:"p"},"Whisper API Key")," will be also be displayed. Save the ",(0,a.kt)("inlineCode",{parentName:"p"},"Whisper API Key")," somewhere safe, you'll need the key to configure the Whisper client."),(0,a.kt)("pre",{parentName:"li"},(0,a.kt)("code",{parentName:"pre",className:"language-text"},"Whisper API Key: <key>\n"))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"To stop the Whisper Transcriber Service, press ",(0,a.kt)("inlineCode",{parentName:"p"},"CTRL+C")," in the terminal.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"To deactivate the Python virtual environment, run ",(0,a.kt)("inlineCode",{parentName:"p"},"deactivate"),"."))))}h.isMDXComponent=!0},6120:(e,t,r)=>{r.d(t,{Z:()=>n});const n=r.p+"assets/images/whisper_model_selection-fe215cf6a783f1f3c31a03892f7bcf8d.png"}}]);