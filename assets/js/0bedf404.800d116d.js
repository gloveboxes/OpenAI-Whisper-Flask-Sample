"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[902],{4137:(e,t,a)=>{a.d(t,{Zo:()=>h,kt:()=>u});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var p=n.createContext({}),s=function(e){var t=n.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},h=function(e){var t=s(e.components);return n.createElement(p.Provider,{value:t},e.children)},m="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,p=e.parentName,h=o(e,["components","mdxType","originalType","parentName"]),m=s(a),c=r,u=m["".concat(p,".").concat(c)]||m[c]||d[c]||i;return a?n.createElement(u,l(l({ref:t},h),{},{components:a})):n.createElement(u,l({ref:t},h))}));function u(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,l=new Array(i);l[0]=c;var o={};for(var p in t)hasOwnProperty.call(t,p)&&(o[p]=t[p]);o.originalType=e,o[m]="string"==typeof e?e:r,l[1]=o;for(var s=2;s<i;s++)l[s]=a[s];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},7779:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>d,frontMatter:()=>i,metadata:()=>o,toc:()=>s});var n=a(7462),r=(a(7294),a(4137));const i={},l="Start the Home Assistant",o={unversionedId:"Assistant",id:"Assistant",title:"Start the Home Assistant",description:"Platform support",source:"@site/docs/20-Assistant.md",sourceDirName:".",slug:"/Assistant",permalink:"/OpenAI-Whisper-Transcriber-Sample/Assistant",draft:!1,editUrl:"https://github.com/gloveboxes/OpenAI-Whisper-Transcriber-Sample/tree/master/docs/docs/20-Assistant.md",tags:[],version:"current",sidebarPosition:20,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Intro to OpenAI Functions",permalink:"/OpenAI-Whisper-Transcriber-Sample/OpenAI-Functions"},next:{title:"Create a Whisper Endpoint",permalink:"/OpenAI-Whisper-Transcriber-Sample/category/create-a-whisper-endpoint"}},p={},s=[{value:"Platform support",id:"platform-support",level:2},{value:"Clone the repository",id:"clone-the-repository",level:2},{value:"Environment file",id:"environment-file",level:2},{value:"Cloud API Keys",id:"cloud-api-keys",level:2},{value:"OpenAI API",id:"openai-api",level:3},{value:"Weather API",id:"weather-api",level:3},{value:"Install prerequisites",id:"install-prerequisites",level:2},{value:"Install OS Dependencies",id:"install-os-dependencies",level:2},{value:"Linux",id:"linux",level:3},{value:"Install the required Python packages:",id:"install-the-required-python-packages",level:2},{value:"Set the Text to Speech Transcriber mode",id:"set-the-text-to-speech-transcriber-mode",level:2},{value:"Run the home assistant app",id:"run-the-home-assistant-app",level:2},{value:"Whisper Models",id:"whisper-models",level:2}],h={toc:s},m="wrapper";function d(e){let{components:t,...i}=e;return(0,r.kt)(m,(0,n.Z)({},h,i,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"start-the-home-assistant"},"Start the Home Assistant"),(0,r.kt)("h2",{id:"platform-support"},"Platform support"),(0,r.kt)("p",null,"The Home Assistant app has been tested on the following platforms:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Windows 11 (latest updates)"),(0,r.kt)("li",{parentName:"ol"},"macOS Ventura (latest updates)"),(0,r.kt)("li",{parentName:"ol"},"Ubuntu 20.04 (latest updates)")),(0,r.kt)("h2",{id:"clone-the-repository"},"Clone the repository"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Install Git from ",(0,r.kt)("a",{parentName:"p",href:"https://git-scm.com/downloads"},"https://git-scm.com/downloads"),".")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Clone the repository:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/gloveboxes/OpenAI-Whisper-Transcriber-Sample\n")))),(0,r.kt)("h2",{id:"environment-file"},"Environment file"),(0,r.kt)("p",null,"You'll find a ",(0,r.kt)("inlineCode",{parentName:"p"},".env")," file in the ",(0,r.kt)("inlineCode",{parentName:"p"},"client")," folder of the repo you cloned. This file contains the configuration settings for the Home Assistant app."),(0,r.kt)("p",null,"The following keys are defined in the ",(0,r.kt)("inlineCode",{parentName:"p"},".env")," file:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Key"),(0,r.kt)("th",{parentName:"tr",align:null},"Description"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"OPENAI_API_KEY"),(0,r.kt)("td",{parentName:"tr",align:null},"The OpenAI API key.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"WEATHER_API_KEY"),(0,r.kt)("td",{parentName:"tr",align:null},"The Weather API key.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"WHISPER_MODE"),(0,r.kt)("td",{parentName:"tr",align:null},"The Whisper speech to text transcriber mode. The default mode is ",(0,r.kt)("inlineCode",{parentName:"td"},"local"),".")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"WHISPER_MODEL_NAME"),(0,r.kt)("td",{parentName:"tr",align:null},"The Whisper speech to text transcriber model name. The default model is ",(0,r.kt)("inlineCode",{parentName:"td"},"tiny"),". This is only used when the ",(0,r.kt)("inlineCode",{parentName:"td"},"WHISPER_MODE")," is set to ",(0,r.kt)("inlineCode",{parentName:"td"},"local"),". See ",(0,r.kt)("a",{parentName:"td",href:"#whisper-models"},"Whisper models")," for more information.")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"WHISPER_ENDPOINT"),(0,r.kt)("td",{parentName:"tr",align:null},"The Whisper speech to text transcriber endpoint. This is only used when the ",(0,r.kt)("inlineCode",{parentName:"td"},"WHISPER_MODE")," is set to ",(0,r.kt)("inlineCode",{parentName:"td"},"gpu"),".")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"WHISPER_API_KEY"),(0,r.kt)("td",{parentName:"tr",align:null},"The Whisper speech to text transcriber API key. This is only used when the ",(0,r.kt)("inlineCode",{parentName:"td"},"WHISPER_MODE")," is set to ",(0,r.kt)("inlineCode",{parentName:"td"},"gpu"),".")))),(0,r.kt)("h2",{id:"cloud-api-keys"},"Cloud API Keys"),(0,r.kt)("p",null,"The Home Assistant uses the following cloud services:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"https://platform.openai.com"},"OpenAI")," chat and depending on your configuration, the ",(0,r.kt)("inlineCode",{parentName:"li"},"Whisper")," speech to text transcriber. The OpenAI API key is used to call the OpenAI Chat Completion API and extracting OpenAI Functions."),(0,r.kt)("li",{parentName:"ol"},"The ",(0,r.kt)("a",{parentName:"li",href:"https://www.weatherapi.com/"},"Weather API")," to get weather data. This data is used to ",(0,r.kt)("inlineCode",{parentName:"li"},"ground")," the GPT prompts the assistant generates.")),(0,r.kt)("p",null,"Next you will need to create accounts and get API keys for the cloud services. The API keys are stored in a ",(0,r.kt)("inlineCode",{parentName:"p"},".env")," file in the ",(0,r.kt)("inlineCode",{parentName:"p"},"client")," folder of the repo you cloned. As you create the API keys, add them to the ",(0,r.kt)("inlineCode",{parentName:"p"},".env")," file."),(0,r.kt)("h3",{id:"openai-api"},"OpenAI API"),(0,r.kt)("p",null,"Create an OpenAI account and get an API key."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Sign up for an OpenAI account at ",(0,r.kt)("a",{parentName:"li",href:"https://platform.openai.com"},"https://platform.openai.com"),"."),(0,r.kt)("li",{parentName:"ol"},"Create an API key at ",(0,r.kt)("a",{parentName:"li",href:"https://platform.openai.com/account/api-keys"},"https://platform.openai.com/account/api-keys"),"."),(0,r.kt)("li",{parentName:"ol"},"Update the OPENAI_API_KEY key in the ",(0,r.kt)("inlineCode",{parentName:"li"},".env")," file with the API key."),(0,r.kt)("li",{parentName:"ol"},"Save the updated ",(0,r.kt)("inlineCode",{parentName:"li"},".env")," file.")),(0,r.kt)("h3",{id:"weather-api"},"Weather API"),(0,r.kt)("p",null,"Create a Weather API account and get an API key."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Sign up for a ",(0,r.kt)("a",{parentName:"li",href:"https://www.weatherapi.com/signup.aspx"},"Weather API account"),"."),(0,r.kt)("li",{parentName:"ol"},"Create a free ",(0,r.kt)("a",{parentName:"li",href:"https://www.weatherapi.com/my/"},"Weather API key"),"."),(0,r.kt)("li",{parentName:"ol"},"Update the WEATHER_API_KEY key in the ",(0,r.kt)("inlineCode",{parentName:"li"},".env")," file with the API key."),(0,r.kt)("li",{parentName:"ol"},"Save the updated ",(0,r.kt)("inlineCode",{parentName:"li"},".env")," file.")),(0,r.kt)("h2",{id:"install-prerequisites"},"Install prerequisites"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Install ",(0,r.kt)("a",{parentName:"li",href:"https://www.python.org/downloads"},"Python")," version 3.8 ~ 3.10. The ",(0,r.kt)("a",{parentName:"li",href:"https://pypi.org/project/openai-whisper/"},"Whisper library")," is supported on Python 3.8 to 3.10.")),(0,r.kt)("h2",{id:"install-os-dependencies"},"Install OS Dependencies"),(0,r.kt)("h3",{id:"linux"},"Linux"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"sudo apt-get install portaudio19-dev python3-pyaudio\n")),(0,r.kt)("h2",{id:"install-the-required-python-packages"},"Install the required Python packages:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"From the command line, change to the ",(0,r.kt)("inlineCode",{parentName:"p"},"client")," folder of the repo you cloned.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Create a Python virtual environment:"),(0,r.kt)("p",{parentName:"li"},"Windows"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-pwsh"},"python -m venv .assistant\n")),(0,r.kt)("p",{parentName:"li"},"Linux and macOS"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"python3 -m venv .assistant\n"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Activate the Python virtual environment:"),(0,r.kt)("p",{parentName:"li"},"Windows"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-pwsh"},"./.assistant/Scripts/activate\n")),(0,r.kt)("p",{parentName:"li"},"Linux and macOS"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"source .assistant/bin/activate\n"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Install the required Python packages:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pip install -r requirements.txt\n"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"On Windows, by default, the ",(0,r.kt)("inlineCode",{parentName:"p"},"requirements.txt")," file will install the CPU version of PyTorch. If you have an NVidia GPU, you can install the CUDA accelerated version of PyTorch."),(0,r.kt)("ol",{parentName:"li"},(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"First uninstall the CPU version of PyTorch:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-pwsh"},"pip3 uninstall torch torchvision torchaudio\n"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Install the CUDA accelerated version of PyTorch:"),(0,r.kt)("p",{parentName:"li"},"Review the ",(0,r.kt)("a",{parentName:"p",href:"https://pytorch.org/get-started/locally/"},"PyTorch website")," for the latest installation instructions."),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n")))))),(0,r.kt)("h2",{id:"set-the-text-to-speech-transcriber-mode"},"Set the Text to Speech Transcriber mode"),(0,r.kt)("p",null,"There are three modes to use Whisper speech to text transcriber. The default mode is ",(0,r.kt)("inlineCode",{parentName:"p"},"local"),". You can change the mode by updating the ",(0,r.kt)("inlineCode",{parentName:"p"},"WHISPER_MODE")," key in the ",(0,r.kt)("inlineCode",{parentName:"p"},".env")," file."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("inlineCode",{parentName:"li"},"local"),": The Whisper speech to text transcription is done locally on the device. This is the default mode and free mode. The speed will depend on the hardware capabilities of your computer. The first time the Whisper speech to text transcriber is used, it will download the transcriber model from the internet. This will take a few minutes."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("inlineCode",{parentName:"li"},"openai"),": The Whisper speech to text transcription is done using the OpenAI API Audio service which maybe a lot faster that transcribing speech on your computer. This is a paid service, review ",(0,r.kt)("a",{parentName:"li",href:"https://openai.com/pricing/"},"OpenAI Audio Model Pricing")," for more information."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("inlineCode",{parentName:"li"},"gpu"),": You can run a Whisper REST endpoint on your own NVidia GPU. For more information, review the ",(0,r.kt)("a",{parentName:"li",href:"../Whisper-Server/Whisper-Server-Setup"},"Whisper REST API")," docs.")),(0,r.kt)("h2",{id:"run-the-home-assistant-app"},"Run the home assistant app"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Ensure the Python virtual environment is activated.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"From the command line, change to the ",(0,r.kt)("inlineCode",{parentName:"p"},"client")," folder of the repo you cloned.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Run the home assistant app:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"python assistant.py\n"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"The App will start, select your preferred microphone from the dropdown menu."),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("img",{alt:"Home Assistant",src:a(4415).Z,width:"3264",height:"1658"}))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"You can tweak the ",(0,r.kt)("inlineCode",{parentName:"p"},"Energy Threshold"),". The Energy Threshold represents the energy level threshold for sounds. Values below this threshold are considered silence, and values above this threshold are considered speech. For more information on this setting, review ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/Uberi/speech_recognition/blob/master/reference/library-reference.rst#recognizer_instanceenergy_threshold--300---type-float"},"recognizer_instance.energy_threshold"),".")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Press ",(0,r.kt)("inlineCode",{parentName:"p"},"Microphone")," button to start listening for your voice commands. Try out a few commands like:"),(0,r.kt)("ol",{parentName:"li"},(0,r.kt)("li",{parentName:"ol"},"What's the weather in Seattle"),(0,r.kt)("li",{parentName:"ol"},"How can you help me"),(0,r.kt)("li",{parentName:"ol"},"Turn on the living room lights"),(0,r.kt)("li",{parentName:"ol"},"Turn in the living room lights set the color to orange and brightness to dim."),(0,r.kt)("li",{parentName:"ol"},"Turn on the washing machine"),(0,r.kt)("li",{parentName:"ol"},"Lock the front door")))),(0,r.kt)("h2",{id:"whisper-models"},"Whisper Models"),(0,r.kt)("p",null,"The Whisper speech to text transcriber default model name is ",(0,r.kt)("inlineCode",{parentName:"p"},"tiny"),". You can change the model name by updating the ",(0,r.kt)("inlineCode",{parentName:"p"},"WHISPER_MODEL_NAME")," key in the ",(0,r.kt)("inlineCode",{parentName:"p"},".env")," file."),(0,r.kt)("p",null,"The following table lists the available Whisper speech to text transcriber model names. The performance of the transcriber will depend on the model name you select and the hardware capabilities of your computer. "),(0,r.kt)("p",null,"Remember, if you don't have the hardware to run the models with sufficient performance, you can use the OpenAI API Audio service by setting the ",(0,r.kt)("inlineCode",{parentName:"p"},"WHISPER_MODE")," environment variable to ",(0,r.kt)("inlineCode",{parentName:"p"},"openai"),". "),(0,r.kt)("p",null,"The OpenAI API Audio service is a paid service, review ",(0,r.kt)("a",{parentName:"p",href:"https://openai.com/pricing/"},"OpenAI Audio Model Pricing")," for more information."),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(6120).Z,width:"1583",height:"568"})))}d.isMDXComponent=!0},4415:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/home_assistant-52ff09e09d57238fb4163a7a59697e74.png"},6120:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/whisper_model_selection-fe215cf6a783f1f3c31a03892f7bcf8d.png"}}]);